Human action recognition from realistic videos attracts more attention in many practical applications such as on-line videosurveillance  and  content-based  video  management.  Single  action  recognition  always  fails  to  distinguish  similar  actioncategories due to the complex background settings in realistic videos. In this paper, a novel action-scene model is exploredto  learn  contextual  relationship  between  actions  and  scenes  in  realistic  videos.  With  little  prior  knowledge  on  scenecategories,  a  generative  probabilistic  framework  is  used  for  action  inference  from  background  directly  based  on  visualwords.  Experimental  results  on  a  realistic  video  dataset  validate  the  effectiveness  of  the  action-scene  model  for  actionrecognition from background settings. Extensive experiments were conducted on different feature extracted methods, andthe results show the learned model has good robustness when the features are noisy.© 2014 The Authors. Published by Elsevier B. V. Open access under CC BY-NC-ND license.© 2013 Published by Elsevier B.V.Peer-review under responsibility of Scientific Committee of American Applied Science Research InstituteSelection and/or peer review under responsibility of American Applied Science Research Institute